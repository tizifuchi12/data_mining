"""
MODELO FINAL OPTIMIZADO
=======================
ConfiguraciÃ³n Ã³ptima encontrada:
- Algoritmo: Gradient Boosting
- Features: speed + acceleration (2 features)
- Frecuencia: 120 segundos (2 minutos)
- Performance: RÂ²=0.522, RMSE=0.420 ml/s
- ReducciÃ³n bandwidth: 99.2%
"""

import pandas as pd
import numpy as np
import glob
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor
import matplotlib.pyplot as plt
import pickle
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# âœ… CONFIGURACIÃ“N Ã“PTIMA (BASADA EN ANÃLISIS DE FRECUENCIA)
# =============================================================================
OPTIMAL_FREQ = '120s'        # âœ… Mejor frecuencia encontrada
RANDOM_SEED = 42
NUM_TRAIN_VEHICLES = 120
MAX_TRAINING_SAMPLES = 1500000

print("="*80)
print("ENTRENAMIENTO DEL MODELO FINAL OPTIMIZADO")
print("="*80)
print(f"""
ðŸŽ¯ CONFIGURACIÃ“N Ã“PTIMA:
   â€¢ Algoritmo: Gradient Boosting (200 Ã¡rboles, depth=7)
   â€¢ Features: speed + acceleration (2 features)
   â€¢ Frecuencia: {OPTIMAL_FREQ} (2 minutos)
   â€¢ ReducciÃ³n bandwidth: 99.2% (vs 1 segundo)
   
ðŸ“Š PERFORMANCE ESPERADA:
   â€¢ RÂ² medio: ~0.52
   â€¢ RÂ² mediano: ~0.61
   â€¢ RMSE: ~0.42 ml/s
   â€¢ VehÃ­culos con RÂ²>0.5: ~70%
""")

# =============================================================================
# FUNCIÃ“N DE PROCESAMIENTO CON FRECUENCIA Ã“PTIMA
# =============================================================================
def process_vehicle_optimal(file_path):
    """Procesa vehÃ­culo con frecuencia Ã³ptima (120s)"""
    try:
        data = pd.read_csv(file_path)
        data['time'] = pd.to_datetime(data['time'], errors='coerce')
        data['time'] = data['time'].dt.floor('s')
        data = data.dropna(subset=['time'])
        
        if len(data) == 0:
            return None
        
        signals = {
            'gps_speed': 'TRACKS.MUNIC.GPS_SPEED (km/h)',
            'obd_speed': 'TRACKS.MUNIC.MDI_OBD_SPEED (km/h)',
            'fuel_consumed': 'TRACKS.MUNIC.MDI_OBD_FUEL (ml)'
        }
        
        dfs = {}
        for signal_name, column_name in signals.items():
            if column_name in data.columns:
                df_signal = data[['time', column_name]].copy()
                df_signal = df_signal.dropna(subset=[column_name])
                df_signal = df_signal.rename(columns={column_name: signal_name})
                df_signal = df_signal.set_index('time')
                dfs[signal_name] = df_signal
        
        if 'fuel_consumed' not in dfs:
            return None
        if 'gps_speed' not in dfs and 'obd_speed' not in dfs:
            return None
        
        # Resamplear a 120s
        resampled = {}
        for signal_name, df in dfs.items():
            resampled[signal_name] = df.resample(OPTIMAL_FREQ).mean()
        
        data_aligned = pd.concat(resampled.values(), axis=1)
        data_aligned.columns = resampled.keys()
        
        # Combinar velocidades
        if 'gps_speed' in data_aligned.columns and 'obd_speed' in data_aligned.columns:
            data_aligned['speed'] = data_aligned['gps_speed'].fillna(data_aligned['obd_speed'])
        elif 'gps_speed' in data_aligned.columns:
            data_aligned['speed'] = data_aligned['gps_speed']
        elif 'obd_speed' in data_aligned.columns:
            data_aligned['speed'] = data_aligned['obd_speed']
        else:
            return None
        
        # InterpolaciÃ³n simple
        for col in ['speed', 'fuel_consumed']:
            if col in data_aligned.columns:
                data_aligned[col] = data_aligned[col].fillna(method='ffill', limit=3)
                data_aligned[col] = data_aligned[col].fillna(method='bfill', limit=3)
        
        data_freq = data_aligned.dropna(subset=['speed', 'fuel_consumed']).copy()
        
        if len(data_freq) < 50:
            return None
        
        # Features
        freq_seconds = 120
        data_freq['acceleration'] = data_freq['speed'].diff()
        data_freq['fuel_increment'] = data_freq['fuel_consumed'].diff()
        data_freq.loc[data_freq['fuel_increment'] < 0, 'fuel_increment'] = np.nan
        data_freq['fuel_rate'] = data_freq['fuel_increment'] / freq_seconds
        
        data_freq = data_freq.replace([np.inf, -np.inf], np.nan)
        data_freq = data_freq.dropna()
        
        if len(data_freq) < 50:
            return None
        
        # Eliminar outliers
        Q1 = data_freq['fuel_rate'].quantile(0.25)
        Q3 = data_freq['fuel_rate'].quantile(0.75)
        IQR = Q3 - Q1
        
        if IQR == 0:
            return None
        
        data_freq = data_freq[(data_freq['fuel_rate'] >= Q1 - 1.5*IQR) & 
                              (data_freq['fuel_rate'] <= Q3 + 1.5*IQR)].copy()
        
        if len(data_freq) < 100:
            return None
        
        return data_freq[['speed', 'acceleration', 'fuel_rate']].copy()
        
    except Exception as e:
        return None

# =============================================================================
# CARGAR Y DIVIDIR DATOS
# =============================================================================
print("\n" + "="*80)
print("CARGANDO DATOS")
print("="*80)

all_files = glob.glob("fuel_data/*.csv")
np.random.seed(RANDOM_SEED)
np.random.shuffle(all_files)

train_files = all_files[:NUM_TRAIN_VEHICLES]
test_files = all_files[NUM_TRAIN_VEHICLES:]

print(f"\nðŸ“‚ DivisiÃ³n:")
print(f"   â€¢ Archivos train: {len(train_files)}")
print(f"   â€¢ Archivos test: {len(test_files)}")

# Procesar train
print(f"\nðŸ”„ Procesando {len(train_files)} vehÃ­culos de entrenamiento...")
train_data_list = []
for i, file in enumerate(train_files):
    if i % 20 == 0:
        print(f"   Progreso: {i}/{len(train_files)}")
    d = process_vehicle_optimal(file)
    if d is not None:
        train_data_list.append(d)

print(f"\nâœ… VehÃ­culos procesados: {len(train_data_list)}/{len(train_files)}")

combined_train = pd.concat(train_data_list, ignore_index=True)
print(f"âœ… Total registros: {len(combined_train):,}")

# Submuestreo si necesario
if len(combined_train) > MAX_TRAINING_SAMPLES:
    print(f"   Submuestreando a {MAX_TRAINING_SAMPLES:,}...")
    combined_train = combined_train.sample(n=MAX_TRAINING_SAMPLES, random_state=RANDOM_SEED)

combined_train = combined_train.replace([np.inf, -np.inf], np.nan)
combined_train = combined_train.dropna()
print(f"âœ… Registros finales: {len(combined_train):,}")

# Preparar datos
feature_cols = ['speed', 'acceleration']
X_train = combined_train[feature_cols].values
y_train = combined_train['fuel_rate'].values

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# =============================================================================
# ENTRENAR MODELO Ã“PTIMO
# =============================================================================
print("\n" + "="*80)
print("ENTRENANDO MODELO GRADIENT BOOSTING")
print("="*80)

model = GradientBoostingRegressor(
    n_estimators=200,
    max_depth=7,
    learning_rate=0.1,
    random_state=RANDOM_SEED,
    verbose=1
)

print("\nðŸ¤– Entrenando Gradient Boosting...")
model.fit(X_train_scaled, y_train)
print("âœ… Modelo entrenado")

# =============================================================================
# EVALUAR EN TEST
# =============================================================================
print("\n" + "="*80)
print(f"EVALUANDO EN {len(test_files)} VEHÃCULOS DE TEST")
print("="*80)

results = []

for i, file in enumerate(test_files):
    if i % 5 == 0:
        print(f"\nProcesando: {i}/{len(test_files)}")
    
    vehicle_id = file.split('\\')[-1].replace('.csv', '')
    test_data = process_vehicle_optimal(file)
    
    if test_data is None:
        continue
    
    X_test = test_data[feature_cols].values
    y_test = test_data['fuel_rate'].values
    
    X_test_scaled = scaler.transform(X_test)
    y_pred = model.predict(X_test_scaled)
    
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    results.append({
        'Vehicle_ID': vehicle_id,
        'RÂ²': r2,
        'RMSE': rmse,
        'N_samples': len(y_test)
    })

df_results = pd.DataFrame(results)

# =============================================================================
# RESULTADOS
# =============================================================================
print("\n" + "="*80)
print("RESULTADOS FINALES")
print("="*80)

r2_mean = df_results['RÂ²'].mean()
r2_median = df_results['RÂ²'].median()
r2_std = df_results['RÂ²'].std()
rmse_mean = df_results['RMSE'].mean()
r2_above_05 = (df_results['RÂ²'] > 0.5).sum()
r2_03_05 = ((df_results['RÂ²'] >= 0.3) & (df_results['RÂ²'] <= 0.5)).sum()
r2_below_03 = (df_results['RÂ²'] < 0.3).sum()

print(f"""
ðŸ“Š MÃ‰TRICAS GLOBALES:
   â€¢ RÂ² medio: {r2_mean:.3f} Â± {r2_std:.3f}
   â€¢ RÂ² mediano: {r2_median:.3f}
   â€¢ RMSE medio: {rmse_mean:.3f} ml/s
   â€¢ VehÃ­culos evaluados: {len(df_results)}

ðŸ“ˆ DISTRIBUCIÃ“N:
   â€¢ RÂ² > 0.5 (bueno):     {r2_above_05}/{len(df_results)} ({r2_above_05/len(df_results)*100:.1f}%)
   â€¢ RÂ² 0.3-0.5 (regular): {r2_03_05}/{len(df_results)} ({r2_03_05/len(df_results)*100:.1f}%)
   â€¢ RÂ² < 0.3 (malo):      {r2_below_03}/{len(df_results)} ({r2_below_03/len(df_results)*100:.1f}%)
""")

# Guardar resultados
df_results.to_csv('optimal_model_results.csv', index=False)
print("âœ… Resultados guardados: 'optimal_model_results.csv'")

# =============================================================================
# GUARDAR MODELO ENTRENADO
# =============================================================================
print("\n" + "="*80)
print("GUARDANDO MODELO")
print("="*80)

# Guardar modelo
with open('optimal_model.pkl', 'wb') as f:
    pickle.dump(model, f)
print("âœ… Modelo guardado: 'optimal_model.pkl'")

# Guardar scaler
with open('optimal_scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
print("âœ… Scaler guardado: 'optimal_scaler.pkl'")

# Guardar configuraciÃ³n
config = {
    'algorithm': 'Gradient Boosting',
    'features': feature_cols,
    'frequency': OPTIMAL_FREQ,
    'n_estimators': 200,
    'max_depth': 7,
    'r2_mean': r2_mean,
    'r2_median': r2_median,
    'rmse_mean': rmse_mean,
    'bandwidth_reduction': 99.2
}

with open('optimal_config.pkl', 'wb') as f:
    pickle.dump(config, f)
print("âœ… ConfiguraciÃ³n guardada: 'optimal_config.pkl'")

# =============================================================================
# VISUALIZACIÃ“N
# =============================================================================
print("\n" + "="*80)
print("GENERANDO VISUALIZACIONES")
print("="*80)

fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# 1. DistribuciÃ³n de RÂ²
ax1 = axes[0, 0]
ax1.hist(df_results['RÂ²'], bins=20, color='steelblue', edgecolor='black', alpha=0.7)
ax1.axvline(r2_mean, color='red', linestyle='--', linewidth=2, label=f'Moyenne: {r2_mean:.3f}')
ax1.axvline(r2_median, color='green', linestyle='--', linewidth=2, label=f'MÃ©diane: {r2_median:.3f}')
ax1.set_xlabel('RÂ² Score', fontsize=12, fontweight='bold')
ax1.set_ylabel('Nombre de vÃ©hicules', fontsize=12, fontweight='bold')
ax1.set_title('Distribution des Scores RÂ²', fontsize=14, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# 2. RÂ² por vehÃ­culo (ordenado)
ax2 = axes[0, 1]
df_sorted = df_results.sort_values('RÂ²', ascending=False).reset_index(drop=True)
colors = ['green' if r2 > 0.5 else 'orange' if r2 > 0.3 else 'red' for r2 in df_sorted['RÂ²']]
ax2.bar(range(len(df_sorted)), df_sorted['RÂ²'], color=colors, edgecolor='black', alpha=0.7)
ax2.axhline(0.5, color='green', linestyle=':', alpha=0.5, label='Seuil bon (0.5)')
ax2.axhline(0.3, color='orange', linestyle=':', alpha=0.5, label='Seuil acceptable (0.3)')
ax2.set_xlabel('VÃ©hicule (triÃ©)', fontsize=12, fontweight='bold')
ax2.set_ylabel('RÂ² Score', fontsize=12, fontweight='bold')
ax2.set_title('Performance par VÃ©hicule', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3, axis='y')

# 3. RMSE vs RÂ²
ax3 = axes[1, 0]
scatter = ax3.scatter(df_results['RÂ²'], df_results['RMSE'], 
                     s=100, alpha=0.6, c=df_results['RÂ²'], cmap='RdYlGn', 
                     edgecolors='black', linewidth=1)
ax3.set_xlabel('RÂ² Score', fontsize=12, fontweight='bold')
ax3.set_ylabel('RMSE (ml/s)', fontsize=12, fontweight='bold')
ax3.set_title('Trade-off RÂ² vs RMSE', fontsize=14, fontweight='bold')
ax3.grid(True, alpha=0.3)
plt.colorbar(scatter, ax=ax3, label='RÂ²')

# 4. MÃ©tricas clave
ax4 = axes[1, 1]
ax4.axis('off')

summary_text = f"""
ðŸ† MODELO FINAL OPTIMIZADO

ðŸ“Š CONFIGURACIÃ“N:
   â€¢ Algoritmo: Gradient Boosting
   â€¢ Features: speed + acceleration
   â€¢ Frecuencia: 120s (2 minutos)
   â€¢ Ãrboles: 200
   â€¢ Profundidad: 7

ðŸ“ˆ PERFORMANCE:
   â€¢ RÂ² medio: {r2_mean:.3f} Â± {r2_std:.3f}
   â€¢ RÂ² mediano: {r2_median:.3f}
   â€¢ RMSE: {rmse_mean:.3f} ml/s

âœ… DISTRIBUCIÃ“N:
   â€¢ VehÃ­culos con RÂ²>0.5: {r2_above_05}/{len(df_results)} ({r2_above_05/len(df_results)*100:.0f}%)
   â€¢ VehÃ­culos con RÂ²>0.3: {r2_above_05+r2_03_05}/{len(df_results)} ({(r2_above_05+r2_03_05)/len(df_results)*100:.0f}%)

ðŸ’° AHORRO:
   â€¢ ReducciÃ³n bandwidth: 99.2%
   â€¢ Datos enviados: 0.8% vs 100%
"""

ax4.text(0.1, 0.5, summary_text, fontsize=13, verticalalignment='center',
         family='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

plt.tight_layout()
plt.savefig('optimal_model_summary.png', dpi=300, bbox_inches='tight')
print("âœ… GrÃ¡fico guardado: 'optimal_model_summary.png'")

print("\n" + "="*80)
print("âœ… ENTRENAMIENTO DEL MODELO Ã“PTIMO COMPLETADO")
print("="*80)

plt.show()